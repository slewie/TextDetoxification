{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip ../data/interim/toxicity_levels.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tox_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>0.014195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>0.065473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tox_level\n",
       "0  if Alkar floods her with her mental waste, it ...   0.981983\n",
       "1  If Alkar is flooding her with psychic waste, t...   0.014195\n",
       "2                        you're becoming disgusting.   0.999039\n",
       "3                          Now you're getting nasty.   0.065473\n",
       "4                      well, we can spare your life.   0.985068"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interim/toxicity_levels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tox_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tox_level\n",
       "0  if Alkar floods her with her mental waste, it ...          1\n",
       "1  If Alkar is flooding her with psychic waste, t...          0\n",
       "2                        you're becoming disgusting.          1\n",
       "3                          Now you're getting nasty.          0\n",
       "4                      well, we can spare your life.          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threeshold = 0.5\n",
    "\n",
    "df['tox_level'] = df['tox_level'].apply(lambda x: 1 if x > threeshold else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно добавить ещё норм препроцессинг с токенизацией стеммингом и прочим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_stage(sample):\n",
    "    model_inputs = tokenizer(sample['text'], padding='max_length', max_length=256, truncation=True)\n",
    "    return model_inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_ids'] = df.apply(lambda x: preprocessing_stage(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ratio = 0.2\n",
    "train, val = train_test_split(\n",
    "    df, stratify=df['tox_level'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    text_list, toxicity_list = [], []\n",
    "    for _toxicity, _text in batch:\n",
    "        text_list.append(_text)\n",
    "        toxicity_list.append(_toxicity)\n",
    "    return torch.LongTensor(text_list).to(device), torch.FloatTensor(toxicity_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_dataloader = data_utils.DataLoader(\n",
    "    train.to_numpy(), batch_size=batch_size, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "val_dataloader = data_utils.DataLoader(\n",
    "    val.to_numpy(), batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(input_dim, 300)\n",
    "        self.fc1 = nn.Linear(300, 100)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, text):\n",
    "        text = self.embedding(text)\n",
    "        x = F.relu(self.fc1(text))\n",
    "        return F.sigmoid(self.fc2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 32128\n",
    "\n",
    "model = TextClassificationModel(vocab_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def train_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    epoch_num=10\n",
    "):\n",
    "    loop = tqdm(\n",
    "        enumerate(loader, 1),\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch_num}: train\",\n",
    "        leave=True,\n",
    "    )\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, batch in loop:\n",
    "        texts, labels = batch\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(texts).squeeze(1)\n",
    "        # loss calculation\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # optimizer run\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loop.set_postfix({\"loss\": train_loss / (i * len(labels))})\n",
    "\n",
    "def val_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    loss_fn,\n",
    "    epoch_num=-1\n",
    "):\n",
    "    \n",
    "    loop = tqdm(\n",
    "        enumerate(loader, 1),\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch_num}: val\",\n",
    "        leave=True,\n",
    "    )\n",
    "    val_loss = 0.0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # evaluation mode\n",
    "        for i, batch in loop:\n",
    "            texts, labels = batch\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(texts).squeeze(1)\n",
    "            # loss calculation\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            total += len(labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            loop.set_postfix({\"loss\": val_loss / total})\n",
    "       \n",
    "    torch.cuda.empty_cache()\n",
    "    return val_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037e3168c7de4781914e131bfcd93d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07156ffe4184e64a2503f5dc850bbdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bf0b6bbf8148e9897fed10e6d2efe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dce57eb8080411183bb2040f9540260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb910ab96a834eeaba3bb728c27aecfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d55594559e244e6a710b2b6ec3e297c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5: val:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e08681b1df9449581932a302fa527bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3173c3fdd5454d51bcf6c76193bce7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabe3599779e4352b86b5c0869f5f863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41b7b903ca440329d5686a327160bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0795df95ef47a89fd7ee47d2996ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e4c59391e0404aad9a97fd5737b477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10: val:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c8f294f92f4348ae91cfdd906bff52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b21ce50fcd4751947bb26ea6d8d1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9781776816427ca25fa9512c99ca29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0939136d068f47ed9b5fef2d1d75b5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184b035dfe3c4980b7c109a42e861a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32beadd333db4726b2ecf146555309af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15: val:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198d5c14a91e48988fabc8735a637f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bdca368bb0487585e64f1552524bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be272d057a2343b99f6c8baf4974e09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae5014af775499e9b58cc1601a3efb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b7b61ea9084624aa5aa3f7741ba51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9197aa6a2916424e8f0634adfdbd7e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20: val:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(1, 21):\n",
    "    train_one_epoch(model, train_dataloader, optimizer, criterion, epoch_num=epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        val_loss = val_one_epoch(model, val_dataloader, criterion, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/toxicity_identifier.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
