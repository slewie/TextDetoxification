{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip ../data/interim/toxicity_levels.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tox_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>0.014195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>0.065473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tox_level\n",
       "0  if Alkar floods her with her mental waste, it ...   0.981983\n",
       "1  If Alkar is flooding her with psychic waste, t...   0.014195\n",
       "2                        you're becoming disgusting.   0.999039\n",
       "3                          Now you're getting nasty.   0.065473\n",
       "4                      well, we can spare your life.   0.985068"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interim/toxicity_levels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tox_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tox_level\n",
       "0  if Alkar floods her with her mental waste, it ...          1\n",
       "1  If Alkar is flooding her with psychic waste, t...          0\n",
       "2                        you're becoming disgusting.          1\n",
       "3                          Now you're getting nasty.          0\n",
       "4                      well, we can spare your life.          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threeshold = 0.5\n",
    "\n",
    "df['tox_level'] = df['tox_level'].apply(lambda x: 1 if x > threeshold else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно добавить ещё норм препроцессинг с токенизацией стеммингом и прочим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_stage(sample):\n",
    "    model_inputs = tokenizer(sample['text'], padding='max_length', max_length=256, truncation=True)\n",
    "    return model_inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_ids'] = df.apply(lambda x: preprocessing_stage(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ratio = 0.2\n",
    "train, val = train_test_split(\n",
    "    df, stratify=df['tox_level'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    text_list, toxicity_list = [], []\n",
    "    for _toxicity, _text in batch:\n",
    "        text_list.append(_text)\n",
    "        toxicity_list.append(_toxicity)\n",
    "    return torch.LongTensor(text_list).to(device), torch.FloatTensor(toxicity_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_dataloader = data_utils.DataLoader(\n",
    "    train.to_numpy(), batch_size=batch_size, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "val_dataloader = data_utils.DataLoader(\n",
    "    val.to_numpy(), batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(input_dim, 300)\n",
    "        self.fc1 = nn.Linear(300, 100)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, text):\n",
    "        text = self.embedding(text)\n",
    "        x = F.relu(self.fc1(text))\n",
    "        return F.sigmoid(self.fc2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 32128\n",
    "\n",
    "model = TextClassificationModel(vocab_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def train_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    epoch_num=10\n",
    "):\n",
    "    loop = tqdm(\n",
    "        enumerate(loader, 1),\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch_num}: train\",\n",
    "        leave=True,\n",
    "    )\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, batch in loop:\n",
    "        texts, labels = batch\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(texts).squeeze(1)\n",
    "        # loss calculation\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # optimizer run\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loop.set_postfix({\"loss\": train_loss / (i * len(labels))})\n",
    "\n",
    "def val_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    loss_fn,\n",
    "    epoch_num=-1\n",
    "):\n",
    "    \n",
    "    loop = tqdm(\n",
    "        enumerate(loader, 1),\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch_num}: val\",\n",
    "        leave=True,\n",
    "    )\n",
    "    val_loss = 0.0\n",
    "    correct_3 = 0\n",
    "    correct_4 = 0\n",
    "    correct_5 = 0\n",
    "    correct_6 = 0\n",
    "    correct_7 = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # evaluation mode\n",
    "        for i, batch in loop:\n",
    "            texts, labels = batch\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(texts).squeeze(1)\n",
    "            # loss calculation\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            # test different threesholds\n",
    "            total += len(labels)\n",
    "            predicted_3 = torch.where(outputs.data > 0.3, 1.0, 0.0)\n",
    "            predicted_4 = torch.where(outputs.data > 0.4, 1.0, 0.0)\n",
    "            predicted_5 = torch.where(outputs.data > 0.5, 1.0, 0.0)\n",
    "            predicted_6 = torch.where(outputs.data > 0.6, 1.0, 0.0)\n",
    "            predicted_7 = torch.where(outputs.data > 0.7, 1.0, 0.0)\n",
    "            \n",
    "            correct_3 += sum(predicted_3 == labels)\n",
    "            correct_4 += sum(predicted_4 == labels)\n",
    "            correct_5 += sum(predicted_5 == labels)\n",
    "            correct_6 += sum(predicted_6 == labels)\n",
    "            correct_7 += sum(predicted_7 == labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            loop.set_postfix({\"loss\": val_loss / total})\n",
    "        print(correct_3 / total, correct_4 / total, correct_5 / total, correct_6 / total, correct_7 / total)\n",
    "       \n",
    "    torch.cuda.empty_cache()\n",
    "    return val_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8690b5ba7e054ccba261d6cb2003431f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1536569694e944018982a289fd43839f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8343dc01069d40b996c193cadb3ed8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb0c70d5dd6424e90f5693d30b917dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7981ee06d4476490557ef67e3cb825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b808a13c2baf41c9a3cf4d4dc712a88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5: val:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7457, device='cuda:0') tensor(0.7680, device='cuda:0') tensor(0.7797, device='cuda:0') tensor(0.7798, device='cuda:0') tensor(0.7605, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4317e0e937ca48158f153505c69ab03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089ddfb29958480a8c0b1f8a035cd0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d058ca0b90146a8956b6433d4512026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5758ba58f4f64b72a10ed4db4c12a18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1124e4d9264a9fb646d97b8428cf79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001026f891bd404a9d3daf2a3c244756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10: val:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7779, device='cuda:0') tensor(0.7816, device='cuda:0') tensor(0.7711, device='cuda:0') tensor(0.7494, device='cuda:0') tensor(0.7188, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3dcfdacd86646d0b13f7637472e0303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb684133e6b44bebe296f45c9753d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b04ef8c0764a3dbe2fbbf76848bb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991992b646e64a4087ffbd49924a093d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb587d2765914cadba4bc8ef0401a48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c72ae6814574bf6b8b4b96940ff08a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15: val:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7548, device='cuda:0') tensor(0.7730, device='cuda:0') tensor(0.7826, device='cuda:0') tensor(0.7796, device='cuda:0') tensor(0.7574, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f142758dcb7c449ebb899faca98e5f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3033f79c110f4fb9bb2e829da5004aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c663a261180348cf9d463e5d7ab17c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b5d25a7d524f2590675e06634d5419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229d2894377a4bfc968f41948d0f7922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20: train:   0%|          | 0/1706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece605cb335e4cec837d7747f2a26166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20: val:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7744, device='cuda:0') tensor(0.7827, device='cuda:0') tensor(0.7776, device='cuda:0') tensor(0.7566, device='cuda:0') tensor(0.7244, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 21):\n",
    "    train_one_epoch(model, train_dataloader, optimizer, criterion, epoch_num=epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        val_loss = val_one_epoch(model, val_dataloader, criterion, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/toxicity_identifier.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
