{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxicity identier\n",
    "\n",
    "I want to create a model that will access the level of toxicity, and use this score as metric or add it to the loss. I will train the simple model with pretrained tokenizer from the model for final solution, embedding layer, several linear layers and output with sigmoid function. Also, I will convert tox_level to integer values and train the model on a classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../data/interim/toxicity_levels.zip\n",
      "warning:  skipped \"../\" path component(s) in ../data/interim/toxicity_levels.csv\n",
      "  inflating: data/interim/toxicity_levels.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip ../data/interim/toxicity_levels.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tox_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>0.014195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>0.065473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tox_level\n",
       "0  if Alkar floods her with her mental waste, it ...   0.981983\n",
       "1  If Alkar is flooding her with psychic waste, t...   0.014195\n",
       "2                        you're becoming disgusting.   0.999039\n",
       "3                          Now you're getting nasty.   0.065473\n",
       "4                      well, we can spare your life.   0.985068"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interim/toxicity_levels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tox_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tox_level\n",
       "0  if Alkar floods her with her mental waste, it ...          1\n",
       "1  If Alkar is flooding her with psychic waste, t...          0\n",
       "2                        you're becoming disgusting.          1\n",
       "3                          Now you're getting nasty.          0\n",
       "4                      well, we can spare your life.          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threeshold = 0.5\n",
    "\n",
    "df['tox_level'] = df['tox_level'].apply(lambda x: 1 if x > threeshold else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_stage(sample):\n",
    "    # in the preprocessing phase, I convert the input text to the list of tokens\n",
    "    model_inputs = tokenizer(sample['text'], padding='max_length', max_length=256, truncation=True)\n",
    "    return model_inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_ids'] = df.apply(lambda x: preprocessing_stage(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ratio = 0.2\n",
    "train, val = train_test_split(\n",
    "    df, stratify=df['tox_level'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    text_list, toxicity_list = [], []\n",
    "    for _toxicity, _text in batch:\n",
    "        text_list.append(_text)\n",
    "        toxicity_list.append(_toxicity)\n",
    "    return torch.LongTensor(text_list).to(device), torch.FloatTensor(toxicity_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_dataloader = data_utils.DataLoader(\n",
    "    train.to_numpy(), batch_size=batch_size, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "val_dataloader = data_utils.DataLoader(\n",
    "    val.to_numpy(), batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(input_dim, 300)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(300, 1000),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1000, 250),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(250, 50),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, text):\n",
    "        text = self.embedding(text)\n",
    "        return F.sigmoid(self.model(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 32128\n",
    "\n",
    "model = TextClassificationModel(vocab_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def train_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    epoch_num=10\n",
    "):\n",
    "    loop = tqdm(\n",
    "        enumerate(loader, 1),\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch_num}: train\",\n",
    "        leave=True,\n",
    "    )\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, batch in loop:\n",
    "        texts, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(texts).squeeze(1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loop.set_postfix({\"loss\": train_loss / (i * len(labels))})\n",
    "\n",
    "def val_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    loss_fn,\n",
    "    epoch_num=-1\n",
    "):\n",
    "    \n",
    "    loop = tqdm(\n",
    "        enumerate(loader, 1),\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch_num}: val\",\n",
    "        leave=True,\n",
    "    )\n",
    "    val_loss = 0.0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, batch in loop:\n",
    "            texts, labels = batch\n",
    "\n",
    "            outputs = model(texts).squeeze(1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            total += len(labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            loop.set_postfix({\"loss\": val_loss / total})\n",
    "       \n",
    "    torch.cuda.empty_cache()\n",
    "    return val_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892b999cc8b54a1c830ac794cb3bef17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1: train:   0%|          | 0/1145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42325a4c99894865aea5ae3c57550bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2: train:   0%|          | 0/1145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0661bc47a8d74dd7a0d575402420a08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2: val:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6cf0a83226457494a1d0e6141567c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3: train:   0%|          | 0/1145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa8ae6845284766bde5b07a55424fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4: train:   0%|          | 0/1145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344eecfe2e584aeab587fdfe86c58f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4: val:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82160dc7b1a246fc98e8e844668055cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5: train:   0%|          | 0/1145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759d23cde0b349eb97556ba110cba505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6: train:   0%|          | 0/1145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8100f3f913f42b694ac2647c3f3fabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6: val:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7f04ab07de40cd96fcafb60385f0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7: train:   0%|          | 0/1145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18236b2bba71476199091aa8d1ea9dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8: train:   0%|          | 0/1145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815a6f7b5ada4bcf872b14ea9007f4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8: val:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0efdfea107421dadeee7bd24ccd465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9: train:   0%|          | 0/1145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e90c7582224addbe6fe6b4cea486e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10: train:   0%|          | 0/1145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e0ae08b1b0411fa043709bb84f0741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10: val:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train_one_epoch(model, train_dataloader, optimizer, criterion, epoch_num=epoch)\n",
    "    if epoch % 2 == 0:\n",
    "        val_loss = val_one_epoch(model, val_dataloader, criterion, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model)\n",
    "model_scripted.save('../models/toxicity_identifier.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_toxicity(model, inference_result, tokenizer=tokenizer):\n",
    "    input_ids = tokenizer(inference_result, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "    print(model(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0362]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "check_toxicity(model, \"I love you so much\")\n",
    "check_toxicity(model, \"I'm famous, and you're dead\")\n",
    "check_toxicity(model, \"And it just helped that you have no morals or integrity\")\n",
    "check_toxicity(model, \"Nolan will destroy it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running some manual tests, I can conclude that this model and its minor modifications do not work as I expected(can't differentiate the toxic and nontoxic phrases, and often produce 1) and I am abandoning my idea of using this model as a metric or part of the loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
